{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Doppleganger_pins.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWd0H0jsoYDF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0aa87541-1a55-4c8a-958a-2fb7bf1c3145"
      },
      "source": [
        "!git clone https://github.com/eKuG/Doppleganger.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Doppleganger'...\n",
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 35 (delta 4), reused 0 (delta 0), pack-reused 27\u001b[K\n",
            "Unpacking objects: 100% (35/35), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3BSTAA1okGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f9613e0-0f85-4354-9cfa-d5469cf9c40f"
      },
      "source": [
        "%cd Doppleganger/\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Doppleganger\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSOQxERKooL0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "e4516ae4-6268-4cb7-8ee0-aa475e1b0fd0"
      },
      "source": [
        "# !pip install -r requirements.txt\n",
        "!pip install face_recognition"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/95/f6c9330f54ab07bfa032bf3715c12455a381083125d8880c43cbe76bb3d0/face_recognition-1.3.0-py2.py3-none-any.whl\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100.2MB 74kB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.0.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face_recognition) (1.18.5)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (19.18.0)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566172 sha256=5aa00aa133829769832063aa78c5f43390dcadc99d59dde3d005a7dd3e7ed8c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/99/18/59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOoMQOYWFFFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaY56gt1o2lJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import face_recognition"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bYdyW-cp0_8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "5dad6ef0-cc05-4ca2-966e-5d31c090452d"
      },
      "source": [
        "\"\"\"\n",
        "Structure:\n",
        "        <test_image>.jpg\n",
        "        <train_dir>/\n",
        "            <person_1>/\n",
        "                <person_1_face-1>.jpg\n",
        "                <person_1_face-2>.jpg\n",
        "                .\n",
        "                .\n",
        "                <person_1_face-n>.jpg\n",
        "           <person_2>/\n",
        "                <person_2_face-1>.jpg\n",
        "                <person_2_face-2>.jpg\n",
        "                .\n",
        "                .\n",
        "                <person_2_face-n>.jpg\n",
        "            .\n",
        "            .\n",
        "            <person_n>/\n",
        "                <person_n_face-1>.jpg\n",
        "                <person_n_face-2>.jpg\n",
        "                .\n",
        "                .\n",
        "                <person_n_face-n>.jpg\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'\\nStructure:\\n        <test_image>.jpg\\n        <train_dir>/\\n            <person_1>/\\n                <person_1_face-1>.jpg\\n                <person_1_face-2>.jpg\\n                .\\n                .\\n                <person_1_face-n>.jpg\\n           <person_2>/\\n                <person_2_face-1>.jpg\\n                <person_2_face-2>.jpg\\n                .\\n                .\\n                <person_2_face-n>.jpg\\n            .\\n            .\\n            <person_n>/\\n                <person_n_face-1>.jpg\\n                <person_n_face-2>.jpg\\n                .\\n                .\\n                <person_n_face-n>.jpg\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrxgGDy-qBDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import svm\n",
        "import os\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import math\n",
        "import textwrap\n",
        "import requests\n",
        "import urllib.request\n",
        "from joblib import dump, load\n",
        "import os.path\n",
        "from os import path\n",
        "import warnings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSVeEEzdlIQK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "431a8f80-5050-428b-8474-44ad738dfffb"
      },
      "source": [
        "!git clone https://github.com/eKuG/train_dir.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'train_dir'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects:  25% (1/4)\u001b[K\rremote: Counting objects:  50% (2/4)\u001b[K\rremote: Counting objects:  75% (3/4)\u001b[K\rremote: Counting objects: 100% (4/4)\u001b[K\rremote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 10033 (delta 0), reused 3 (delta 0), pack-reused 10029\u001b[K\n",
            "Receiving objects: 100% (10033/10033), 74.52 MiB | 29.55 MiB/s, done.\n",
            "Resolving deltas: 100% (1771/1771), done.\n",
            "Checking out files: 100% (19858/19858), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVWiRTa6qN_I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eea40c10-f41e-4134-e711-5d3a147715c3"
      },
      "source": [
        "%cd Doppleganger/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Doppleganger\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtLBpLh2k6zx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "574dfe0a-9b2f-44b1-d5b8-cb9f3c7e28f6"
      },
      "source": [
        "%cd ../"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPTM-Tr2lPuW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a26a5aee-0523-4b53-ee44-973c61dd24f3"
      },
      "source": [
        "import shutil,sys\n",
        "shutil.move(\"/content/train_dir/train_dir/train_dir\", \"/content/Doppleganger\") \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'/content/Doppleganger/train_dir'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiQ572xy55Fm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c6b6f4df-6014-4f94-f699-d59d9bf89419"
      },
      "source": [
        "!unzip clf.joblib.zip\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  clf.joblib.zip\n",
            "  inflating: clf.joblib              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNCTjogWqUIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "    # Training the SVC classifier\n",
        "\n",
        "    # The training data would be all the face encodings from all the known images and the labels are their names\n",
        "    encodings = []\n",
        "    names = []\n",
        "\n",
        "    # Training directory\n",
        "    train_dir = os.listdir(\"train_dir/\")\n",
        "\n",
        "    # Loop through each person in the training directory\n",
        "    for person in train_dir:\n",
        "        pix = os.listdir(\"train_dir/\" + person)\n",
        "        # pix = [item for item in pix if not item.startswith('.') and os.path.isfile(os.path.join(root, item))]\n",
        "\n",
        "        # Loop through each training image for the current person\n",
        "        for person_img in pix:\n",
        "            # Get the face encodings for the face in each image file\n",
        "            # if person_img == \".DS_Store\":\n",
        "            #     continue\n",
        "            face = face_recognition.load_image_file(\n",
        "                \"train_dir/\" + person + \"/\" + person_img\n",
        "            )\n",
        "            face_bounding_boxes = face_recognition.face_locations(face)\n",
        "\n",
        "            if len(face_bounding_boxes) == 1:\n",
        "                face_enc = face_recognition.face_encodings(face)[0]\n",
        "                # Add face encoding for current image with corresponding label (name) to the training data\n",
        "                encodings.append(face_enc)\n",
        "                names.append(person)\n",
        "\n",
        "    # Create and train the SVC classifier\n",
        "    clf = svm.SVC(gamma=\"scale\", probability=True)\n",
        "    clf.fit(encodings, names)\n",
        "    dump(clf, 'clf.joblib')\n",
        "    return clf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHyXAQ8PqfOB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def match(clf, filename):\n",
        "\n",
        "    # Load the test image with unknown faces into a numpy array\n",
        "    test_image = face_recognition.load_image_file(filename)\n",
        "\n",
        "    # Find all the faces in the test image using the default HOG-based model\n",
        "    face_locations = face_recognition.face_locations(test_image)\n",
        "    no = len(face_locations)\n",
        "    print(\"\\nNumber of faces detected: \", no)\n",
        "\n",
        "    # Predict all the faces in the test image using the trained classifier\n",
        "    firstname = None\n",
        "    print(\"\\n(â˜žï¾Ÿãƒ®ï¾Ÿ)â˜ž   â˜œ(ï¾Ÿãƒ®ï¾Ÿâ˜œ)\\n\")\n",
        "    print(\"Found:\")\n",
        "    for i in range(no):\n",
        "        test_image_enc = face_recognition.face_encodings(test_image)[i]\n",
        "        name = clf.predict([test_image_enc])\n",
        "        probs = clf.predict_proba([test_image_enc])\n",
        "        print(*name)\n",
        "        firstname = (str(name[0]))\n",
        "    return (firstname, no)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkyxvfZJqhMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_image(actorname, my_img_file, no):\n",
        "    if no > 1:\n",
        "        my_im = Image.open(my_img_file)\n",
        "        my_im.show()\n",
        "        return\n",
        "\n",
        "    canvas_width = 500\n",
        "    canvas_height = 500\n",
        "\n",
        "    # format name\n",
        "    if actorname.split()[-1] == 'face':\n",
        "        actorname = ' '.join(actorname.split()[:-1])\n",
        "    actorname = ''.join(map(lambda x: x if x.islower() else \" \"+x, actorname))\n",
        "\n",
        "    nospaces = actorname.replace(\" \", \"\")\n",
        "    nospaces = ' '.join(nospaces.split())\n",
        "\n",
        "    # call CS API\n",
        "    URL = \"https://www.googleapis.com/customsearch/v1?\"\n",
        "    # NOTE: you need to get a Google Custom Search API Key Here: https://developers.google.com/custom-search/v1/overview\n",
        "    # And A Custom Search Key Here: https://cse.google.com/cse/create/new\n",
        "    # Following these specifications:\n",
        "    # Image Search: On, Search Entire Web: On, Schema.org TypeL Person, Sites to Search: None\n",
        "    PARAMS = {\n",
        "        \"key\" : \"AIzaSyAtKiLuT_iPmOQ4UI0rGyQD-I27QSiWkAs\",\n",
        "        \"cx\" : \"012963635438081633662:wjzt4spyice\",\n",
        "        \"q\": nospaces,\n",
        "        \"searchType\": \"image\",\n",
        "    }\n",
        "\n",
        "    # get resulting image\n",
        "    data = requests.get(url=URL, params=PARAMS).json()\n",
        "    imgurl = (data['items'][0]['link'])\n",
        "\n",
        "    # save the image\n",
        "    try:\n",
        "        with urllib.request.urlopen(imgurl) as url:\n",
        "            with open('temp.jpg', 'wb') as f:\n",
        "                f.write(url.read())\n",
        "    except Exception:\n",
        "        imgurl = (data['items'][1]['link'])\n",
        "        with urllib.request.urlopen(imgurl) as url:\n",
        "            with open('temp.jpg', 'wb') as f:\n",
        "                f.write(url.read())\n",
        "\n",
        "    # ignore warnings\n",
        "    warnings.filterwarnings(\"ignore\", \"(Possibly )?corrupt EXIF data\", UserWarning)\n",
        "\n",
        "    # open image\n",
        "    im = Image.open(urllib.request.urlopen(imgurl))\n",
        "    basewidth = 250\n",
        "\n",
        "    # TODO: if proportions of an image are off (too tall), the cropping will distort the image\n",
        "\n",
        "    # resize actor image\n",
        "    wpercent = (basewidth/float(im.size[0]))\n",
        "    hsize1 = int((float(im.size[1])*float(wpercent)))\n",
        "    im = im.resize((basewidth,hsize1), Image.ANTIALIAS)\n",
        "    old_width, old_height = im.size\n",
        "\n",
        "    # rescale user image\n",
        "    myimg = Image.open(my_img_file)\n",
        "    hpercent = (old_height/float(myimg.size[0]))\n",
        "    wsize = int((float(myimg.size[0])*float(hpercent)))\n",
        "    myimg = myimg.resize((wsize,old_height), Image.ANTIALIAS) # resize to be same height\n",
        "\n",
        "    # crop to be right width\n",
        "    my_width, my_height = myimg.size\n",
        "    if my_width > 300:\n",
        "        diff = my_width - 300\n",
        "        left = (my_width - basewidth) / 2\n",
        "        myimg = myimg.crop((left, 0, left + basewidth, my_height))\n",
        "\n",
        "\n",
        "    old_width, old_height = myimg.size\n",
        "\n",
        "    images = [myimg, im]\n",
        "    widths, heights = zip(*(i.size for i in images))\n",
        "\n",
        "    total_width = sum(widths)\n",
        "    max_height = max(heights)\n",
        "\n",
        "    # format background of canvas\n",
        "    mode = myimg.mode\n",
        "    if len(mode) == 1:  # L, 1\n",
        "        new_background = (255)\n",
        "    if len(mode) == 3:  # RGB\n",
        "        new_background = (255, 255, 255)\n",
        "    if len(mode) == 4:  # RGBA, CMYK\n",
        "        new_background = (255, 255, 255, 255)\n",
        "\n",
        "    new_im = Image.new(mode, (500,500), new_background)\n",
        "\n",
        "    x_offset = 0\n",
        "    for im in images:\n",
        "        new_im.paste(im, (x_offset,100))\n",
        "        x_offset += im.size[0]\n",
        "\n",
        "    # add image to canvas\n",
        "    draw = ImageDraw.Draw(new_im)\n",
        "\n",
        "    # get font\n",
        "    fontsize = 15\n",
        "    txt = f'Your DoppelgÃ¤nger is {actorname.title()}!!'\n",
        "    font = ImageFont.truetype(\"kollektif.ttf\", fontsize)\n",
        "\n",
        "    while font.getsize(txt)[0] < 480:\n",
        "        # iterate until the text size is just larger than the criteria\n",
        "        fontsize += 1\n",
        "        font = ImageFont.truetype(\"kollektif.ttf\", fontsize)\n",
        "\n",
        "    # format and add text\n",
        "    text = textwrap.fill(txt, width=50)\n",
        "    draw.multiline_text((10,30),text, fill='black', font=font, align=\"center\", spacing = 6) #drawing text on the black strip\n",
        "\n",
        "\n",
        "    new_im.show()\n",
        "    new_im.save('result.jpg')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gzm8z47qjAL",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "outputId": "5262677b-235f-4738-9618-09b6d25e9c9e"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "def main():\n",
        "    # didn't have time to sort data to implement this, but it's not really needed\n",
        "    # gender = input('Pick the gender of your celebrity doppleganger: (F)emale, (M)ale, or (B)oth').lower()[0]\n",
        "    # while (gender not in ['f', 'm', 'b']):\n",
        "    #     gender = input('Invalid input. \\\n",
        "    #         Pick the gender of your celebrity doppleganger: (F)emale, (M)ale, or (B)oth').lower()[0]\n",
        "\n",
        "    # industry = input('Pick a film industry for your celebrity doppleganger (all works best!): (H)ollywood, (B)ollywood, (T)ollywood')\n",
        "    # while (gender not in ['h', 'b', 't']):\n",
        "    #     gender = input('Invalid input. \\\n",
        "    #         Pick a film industry for your celebrity doppleganger (all works best!): (H)ollywood, (B)ollywood, (T)ollywood').lower()[0]\n",
        "\n",
        "    print(\"\\n===================================================================\")\n",
        "    # print(\"Welcome to the Celebrity Doppleganger Finder!\\n\\n\")\n",
        "    print(\"\\nWelcome to the\")\n",
        "    print(\"\"\"\n",
        "   ____     _      _          _ _\n",
        "  / ___|___| | ___| |__  _ __(_) |_ _   _\n",
        " | |   / _ \\ |/ _ \\ '_ \\| '__| | __| | | |\n",
        " | |__|  __/ |  __/ |_) | |  | | |_| |_| |\n",
        "  \\____\\___|_|\\___|_.__/|_|  |_|\\__|\\__, |\n",
        "  ____                         _    |___/  _\n",
        " |  _ \\  ___  _ __  _ __   ___| | __ _(_)_(_)_ __   __ _  ___ _ __\n",
        " | | | |/ _ \\| '_ \\| '_ \\ / _ \\ |/ _` |/ _` | '_ \\ / _` |/ _ \\ '__|\n",
        " | |_| | (_) | |_) | |_) |  __/ | (_| | (_| | | | | (_| |  __/ |\n",
        " |____/ \\___/| .__/| .__/ \\___|_|\\__, |\\__,_|_| |_|\\__, |\\___|_|\n",
        "  _____ _    |_|   |_|           |___/             |___/\n",
        " |  ___(_)_ __   __| | ___ _ __\n",
        " | |_  | | '_ \\ / _` |/ _ \\ '__|\n",
        " |  _| | | | | | (_| |  __/ |\n",
        " |_|   |_|_| |_|\\__,_|\\___|_|\n",
        "    \"\"\")\n",
        "\n",
        "    # load classifier\n",
        "    if path.exists('clf.joblib'):\n",
        "        clf = load('clf.joblib')\n",
        "    else:\n",
        "        clf = train()\n",
        "    print(\"The Machine Learning Model has been trained! ðŸ§ \\n\\nNow, let's find your match.\\n\")\n",
        "\n",
        "    uploaded =files.upload()\n",
        "    for fn in uploaded.keys():\n",
        "      print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))\n",
        "      res, no = match(clf, fn)\n",
        "      print(\"https://www.google.com/search?tbm=isch&q=\" + res)\n",
        "      print(\"\\n===================================================================\\n\")\n",
        "\n",
        "        # filename = \"\"\n",
        "        # while not os.path.isfile(filename):\n",
        "        #     filename = input(\"Which file would you like to use? Press enter to default to test_image.jpg: \")\n",
        "        #     if filename == \"\":\n",
        "        #         filename = \"test_image.jpg\"\n",
        "        #         break\n",
        "        #     elif filename == 'q': # exit out of program\n",
        "        #         return\n",
        "        #     elif os.path.isfile(filename):\n",
        "        #         break\n",
        "        #     else:\n",
        "        #         print(\"Invalid file name. Try again.\\n\")\n",
        "\n",
        "        \n",
        "        \n",
        "        # generate_image(res, filename, no)\n",
        "        \n",
        "\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "===================================================================\n",
            "\n",
            "Welcome to the\n",
            "\n",
            "   ____     _      _          _ _\n",
            "  / ___|___| | ___| |__  _ __(_) |_ _   _\n",
            " | |   / _ \\ |/ _ \\ '_ \\| '__| | __| | | |\n",
            " | |__|  __/ |  __/ |_) | |  | | |_| |_| |\n",
            "  \\____\\___|_|\\___|_.__/|_|  |_|\\__|\\__, |\n",
            "  ____                         _    |___/  _\n",
            " |  _ \\  ___  _ __  _ __   ___| | __ _(_)_(_)_ __   __ _  ___ _ __\n",
            " | | | |/ _ \\| '_ \\| '_ \\ / _ \\ |/ _` |/ _` | '_ \\ / _` |/ _ \\ '__|\n",
            " | |_| | (_) | |_) | |_) |  __/ | (_| | (_| | | | | (_| |  __/ |\n",
            " |____/ \\___/| .__/| .__/ \\___|_|\\__, |\\__,_|_| |_|\\__, |\\___|_|\n",
            "  _____ _    |_|   |_|           |___/             |___/\n",
            " |  ___(_)_ __   __| | ___ _ __\n",
            " | |_  | | '_ \\ / _` |/ _ \\ '__|\n",
            " |  _| | | | | | (_| |  __/ |\n",
            " |_|   |_|_| |_|\\__,_|\\___|_|\n",
            "    \n",
            "The Machine Learning Model has been trained! ðŸ§ \n",
            "\n",
            "Now, let's find your match.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b2183a57-74e5-4143-b9c8-af1d44f59515\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b2183a57-74e5-4143-b9c8-af1d44f59515\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving 12592344_1072598259458048_1285727641437590907_n.jpg to 12592344_1072598259458048_1285727641437590907_n.jpg\n",
            "User uploaded file \"12592344_1072598259458048_1285727641437590907_n.jpg\" with length 76551 bytes\n",
            "\n",
            "Number of faces detected:  2\n",
            "\n",
            "(â˜žï¾Ÿãƒ®ï¾Ÿ)â˜ž   â˜œ(ï¾Ÿãƒ®ï¾Ÿâ˜œ)\n",
            "\n",
            "Found:\n",
            "PareshRaval\n",
            "Madhu\n",
            "https://www.google.com/search?tbm=isch&q=Madhu\n",
            "\n",
            "===================================================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_LETmuKwG2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import files\n",
        "# files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}